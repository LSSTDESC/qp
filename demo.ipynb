{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `qp` Demo\n",
    "\n",
    "In this notebook we use the `qp` module to approximate some standard 1-D PDFs using sets of quantiles, and assess the accuracy of the quantile parametrization(TM).\n",
    "\n",
    "### Requirements\n",
    "\n",
    "To run `qp`, you will need to first install the module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "import scipy.interpolate as spi\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `qp.PDF` Class\n",
    "\n",
    "This is the basic element of `qp` - an object representing a probability density function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This now exists in a separate module.  Classes will not appear in the notebook!\n",
    "\n",
    "# class PDF(object):\n",
    "    \n",
    "#     def __init__(self, truth=None):\n",
    "#         self.truth = truth\n",
    "        \n",
    "#     def evaluate(self, loc):\n",
    "        \n",
    "#         return\n",
    "        \n",
    "#     def integrate(self, bounds):\n",
    "        \n",
    "#         return\n",
    "        \n",
    "#     def quantize(self):\n",
    "        \n",
    "#         return\n",
    "        \n",
    "#     def interpolate(self):\n",
    "        \n",
    "#         return\n",
    "        \n",
    "#     def plot(self, limits):\n",
    "        \n",
    "#         x = np.linspace(limits[0], limits[1], 100)\n",
    "#         plt.plot(x, self.truth.pdf(x), 'r-', lw=5, alpha=0.6, label='true pdf')\n",
    "#         plt.legend()\n",
    "#         plt.xlabel('x')\n",
    "#         plt.ylabel('probability density')\n",
    "#         plt.savefig('plot.png')\n",
    "        \n",
    "#         return\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating a Gaussian\n",
    "\n",
    "Let's summon a PDF object, and initialize it with a standard functiom - a Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist = sps.norm(loc=0, scale=1)\n",
    "p = pdf.PDF(truth=dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the PDF object in order to compare the truth and the approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1         0.18888889  0.27777778  0.36666667  0.45555556  0.54444444\n",
      "  0.63333333  0.72222222  0.81111111  0.9       ]\n",
      "[-1.28155157 -0.88199821 -0.5894558  -0.34069483 -0.11163715  0.11163715\n",
      "  0.34069483  0.5894558   0.88199821  1.28155157]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEPCAYAAACgFqixAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e47fb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bounds = (-5.0, 5.0)\n",
    "npoints = 10\n",
    "p.plot(limits=bounds, num_points=npoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant code I've already written for other purposes below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# util-sim module defines handy tools used in data generation\n",
    "# \"\"\"\n",
    "\n",
    "# import sys\n",
    "# import numpy as np\n",
    "# import scipy as sp\n",
    "# #import random\n",
    "# import bisect\n",
    "\n",
    "# np.random.seed(seed=0)\n",
    "\n",
    "# def lrange(x):\n",
    "#     \"\"\"\n",
    "#     lrange makes a range based on the length of a list or array l\n",
    "#     \"\"\"\n",
    "#     return xrange(len(x))\n",
    "\n",
    "# def safelog(xarr):\n",
    "#     \"\"\"\n",
    "#     safelog takes log of array with zeroes\n",
    "#     \"\"\"\n",
    "#     shape = np.shape(xarr)\n",
    "#     flat = xarr.flatten()\n",
    "#     logged = np.log(np.array([max(x,sys.float_info.epsilon) for x in flat]))\n",
    "#     return logged.reshape(shape)\n",
    "\n",
    "# def extend(arr,front,back):\n",
    "#     \"\"\"\n",
    "#     extend appends zeroes to ends of array\n",
    "#     \"\"\"\n",
    "#     return np.concatenate((np.array([sys.float_info.epsilon]*len(front)),arr,np.array([sys.float_info.epsilon]*len(back))),axis=0)\n",
    "\n",
    "# # tools for sampling an arbitrary discrete distribution, used in data generation\n",
    "# def cdf(weights):\n",
    "#     \"\"\"\n",
    "#     cdf takes weights and makes them a normalized CDF\n",
    "#     \"\"\"\n",
    "#     tot = sum(weights)\n",
    "#     result = []\n",
    "#     cumsum = 0.\n",
    "#     for w in weights:\n",
    "#       cumsum += w\n",
    "#       result.append(cumsum/tot)\n",
    "#     return result\n",
    "\n",
    "# def choice(pop, weights):\n",
    "#     \"\"\"\n",
    "#     choice takes a population and assigns each element a value from 0 to len(weights) based on CDF of weights\n",
    "#     \"\"\"\n",
    "#     assert len(pop) == len(weights)\n",
    "#     cdf_vals = cdf(weights)\n",
    "#     x = np.random.random()\n",
    "#     index = bisect.bisect(cdf_vals,x)\n",
    "#     return pop[index]\n",
    "\n",
    "# def normed(x,scale):\n",
    "#     \"\"\"\n",
    "#     normed takes a numpy array and returns a normalized version of it that integrates to 1\n",
    "#     \"\"\"\n",
    "#     x = np.array(x)\n",
    "#     scale = np.array(scale)\n",
    "#     norm = x/np.dot(x,scale)\n",
    "#     return norm\n",
    "\n",
    "# class tnorm(object):\n",
    "#     def __init__(self,mu,sig,ends):\n",
    "#         self.mu = mu\n",
    "#         self.sig = sig\n",
    "#         (self.min,self.max) = ends\n",
    "#         self.lo = self.loc(self.min)\n",
    "#         self.hi = self.loc(self.max)\n",
    "\n",
    "#     def loc(self,z):\n",
    "#         return (z-self.mu)/self.sig\n",
    "\n",
    "#     def phi(self,z):\n",
    "#         x = z/np.sqrt(2)\n",
    "#         term = sp.special.erf(x)\n",
    "#         return (1.+term)/2.\n",
    "\n",
    "#     def norm(self):\n",
    "#         return max(sys.float_info.epsilon,self.phi(self.hi)-self.phi(self.lo))\n",
    "\n",
    "#     def pdf(self,z):\n",
    "#         x = self.loc(z)\n",
    "#         pdf = sp.stats.norm.pdf(x)\n",
    "#         return pdf/(self.sig*self.norm())\n",
    "\n",
    "#     def cdf(self,z):\n",
    "#         x = self.loc(z)\n",
    "#         cdf = self.phi(x)-self.phi(self.lo)\n",
    "#         result = cdf/self.norm()\n",
    "#         #print('a cdf: {}/{}'.format(result,z))\n",
    "#         return result\n",
    "\n",
    "#     def rvs(self,J):\n",
    "#         func = sp.stats.truncnorm(self.lo,self.hi,loc=self.mu,scale=self.sig)\n",
    "#         return func.rvs(size=J)\n",
    "\n",
    "# class gmix(object):\n",
    "#     \"\"\"\n",
    "#     gmix object takes a numpy array of Gaussian parameters and enables computation of PDF\n",
    "#     \"\"\"\n",
    "#     def __init__(self,inarr,bounds):\n",
    "\n",
    "#         self.minZ,self.maxZ = bounds\n",
    "#         self.comps = inarr\n",
    "#         self.ncomps = len(self.comps)\n",
    "\n",
    "#         self.weights = np.transpose(self.comps)[2]\n",
    "#         self.weights = self.weights/sum(self.weights)\n",
    "# #         mincomps = [(self.minZ-comp[0])/comp[1] for comp in self.comps]\n",
    "# #         maxcomps = [(self.maxZ-comp[0])/comp[1] for comp in self.comps]\n",
    "#         self.comps = [tnorm(comp[0],comp[1],(self.minZ,self.maxZ)) for comp in self.comps]#[sp.stats.truncnorm(mincomps[c],maxcomps[c],loc=self.comps[c][0],scale=self.comps[c][1]) for c in lrange(self.comps)]\n",
    "# #         self.comps = [tnorm(comp[0],comp[1],(self.minZ,self.maxZ)) for comp in self.comps]\n",
    "# #         self.weights = np.array([self.calccdf(c,self.minZ,self.maxZ) for c in lrange(self.comps)])\n",
    "\n",
    "#     def pdfs(self,zs):\n",
    "#         print('zs.shape={}'.format(np.shape(zs)))\n",
    "#         out = np.array([self.weights[c]*self.comps[c].pdf(zs) for c in xrange(self.ncomps)])\n",
    "#         print('pdfs.out.shape={}'.format(np.shape(out)))\n",
    "#         return out\n",
    "\n",
    "#     def pdf(self,zs):\n",
    "#         out = np.sum(self.pdfs(zs),axis=0)\n",
    "#         print('pdf.out.shape={}'.format(np.shape(out)))\n",
    "#         return out\n",
    "\n",
    "#     def cdfs(self,zs):\n",
    "#         out = np.array([self.weights[c]*self.comps[c].cdf(zs) for c in xrange(self.ncomps)])\n",
    "#         return out\n",
    "\n",
    "#     def cdf(self,zs):\n",
    "#         out = np.sum(self.cdfs(zs),axis=0)\n",
    "#         return out\n",
    "\n",
    "#     def binned(self,zs):\n",
    "#         thing = self.cdf(zs)\n",
    "#         return thing[1:]-thing[:-1]\n",
    "\n",
    "#     def sample(self,N):\n",
    "#         choices = [0]*self.ncomps\n",
    "#         for j in xrange(N):\n",
    "#             choices[choice(xrange(self.ncomps), self.weights)] += 1\n",
    "#         samps = np.array([])\n",
    "#         for c in xrange(self.ncomps):\n",
    "#             j = choices[c]\n",
    "#             Zs = self.comps[c].rvs(j)\n",
    "#             samps = np.concatenate((samps,Zs))\n",
    "#         return np.array(samps)\n",
    "\n",
    "# class cont(object):\n",
    "#     \"\"\"\n",
    "#     cont object takes a numpy array of normalized discrete distribution and its range and enables computation of PDF\n",
    "#     \"\"\"\n",
    "#     def __init__(self,inarr,bounds):\n",
    "\n",
    "#         self.ndim = len(inarr)\n",
    "#         self.Zs = bounds\n",
    "#         self.difs = self.Zs[1:]-self.Zs[:-1]\n",
    "#         self.weights = inarr/np.dot(inarr,self.difs)\n",
    "# #         mincomps = [(self.minZ-comp[0])/comp[1] for comp in self.comps]\n",
    "# #         maxcomps = [(self.maxZ-comp[0])/comp[1] for comp in self.comps]\n",
    "#         self.dims = [uniform(loc=self.Zs[k],scale=self.difs[k]) for k in xrange(self.ndim)]#[sp.stats.truncnorm(mincomps[c],maxcomps[c],loc=self.comps[c][0],scale=self.comps[c][1]) for c in lrange(self.comps)]\n",
    "# #         self.comps = [tnorm(comp[0],comp[1],(self.minZ,self.maxZ)) for comp in self.comps]\n",
    "# #         self.weights = np.array([self.calccdf(c,self.minZ,self.maxZ) for c in lrange(self.comps)])\n",
    "\n",
    "#     def pdf(self,zs):\n",
    "#         out = np.array([self.weights[k]*np.array([self.dims[k].pdf(z) for z in zs]) for k in xrange(self.ndim)])\n",
    "#         return out\n",
    "\n",
    "#     def cdf(self,zs):\n",
    "#         out = np.array([self.weights[k]*np.array([self.dims[k].cdf(z) for z in zs]) for k in xrange(self.ndim)])\n",
    "#         return out\n",
    "\n",
    "#     def sample(self,N):\n",
    "#         choices = [0]*self.ndim\n",
    "#         for j in xrange(N):\n",
    "#             choices[choice(xrange(self.ndim), self.weights)] += 1\n",
    "#         samps = np.array([])\n",
    "#         for k in xrange(self.ndim):\n",
    "#             j = choices[k]\n",
    "#             Zs = self.dims[k].rvs(j)\n",
    "#             samps = np.concatenate((samps,Zs))\n",
    "#         return np.array(samps)\n",
    "\n",
    "# def makelf(truZ,zfactor,elements,outlier=None):#,dgen=None):\n",
    "\n",
    "#     if outlier is None:\n",
    "#         outlier = []\n",
    "\n",
    "#     mixmod = [[truZ+elem.shift,elem.stddev*zfactor,elem.weight] for elem in elements]\n",
    "#     mixmod.extend([[elem.obsZ,elem.stddev,elem.weight] for elem in outlier])\n",
    "\n",
    "#     lf = mixmod\n",
    "\n",
    "#     return(lf)#,dgen)\n",
    "\n",
    "# def makepdf(grid,truZ,gal,intp=None,dgen=None,outlier=None):\n",
    "\n",
    "#     elements = gal.elements\n",
    "\n",
    "#     zfactor = gal.makezfactor(truZ)\n",
    "\n",
    "#     difs = grid[1:]-grid[:-1]\n",
    "#     dif = difs[np.argmin(grid-truZ)]\n",
    "#     allsummed = np.zeros(len(grid)-1)\n",
    "\n",
    "#     lf = makelf(truZ,zfactor,elements,outlier=outlier)#,dgen)\n",
    "\n",
    "#     pdf = gmix(lf,(min(grid),max(grid)))\n",
    "\n",
    "#     if dgen != None:\n",
    "#         dgdist = gmix(dgen,(min(grid),max(grid)))\n",
    "#         const = dgdist.pdf(truZ)*dif\n",
    "#     else:\n",
    "#         const = 0.\n",
    "\n",
    "#     cdf = pdf.cdf(grid)\n",
    "#     spread = cdf[1:]-cdf[:-1]\n",
    "#     allsummed += spread\n",
    "#     allsummed += const\n",
    "#     if intp != None:\n",
    "#         pf = intp*allsummed\n",
    "#     else:\n",
    "#         pf = allsummed\n",
    "#     pf = np.array(pf)\n",
    "#     #pf = pf/max(np.dot(pf,difs),sys.float_info.epsilon)\n",
    "\n",
    "#     return(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# util-mcmc module defines handy tools for MCMC\n",
    "# \"\"\"\n",
    "\n",
    "# import sys\n",
    "# import numpy as np\n",
    "# import statistics\n",
    "# import cPickle as cpkl\n",
    "# import scipy as sp\n",
    "\n",
    "# def lrange(l):\n",
    "#     \"\"\"\n",
    "#     lrange(l) makes a range based on the length of a list or array l\n",
    "#     \"\"\"\n",
    "#     return xrange(len(l))\n",
    "\n",
    "# def safelog(xarr):\n",
    "#     \"\"\"\n",
    "#     safelog takes log of array with zeroes\n",
    "#     \"\"\"\n",
    "#     shape = np.shape(xarr)\n",
    "#     flat = xarr.flatten()\n",
    "#     logged = np.log(np.array([max(x,sys.float_info.epsilon) for x in flat]))\n",
    "#     return logged.reshape(shape)\n",
    "\n",
    "# def normed(x,scale):\n",
    "#     \"\"\"\n",
    "#     normed takes a numpy array and returns a normalized version of it that integrates to 1\n",
    "#     \"\"\"\n",
    "#     x = np.array(x)\n",
    "#     scale = np.array(scale)\n",
    "#     norm = x/np.dot(x,scale)\n",
    "#     return norm\n",
    "\n",
    "# class mvn(object):\n",
    "#     \"\"\"\n",
    "#     mvn object is multivariate normal distribution, to be used in data generation and prior to emcee\n",
    "#     \"\"\"\n",
    "#     def __init__(self, mean, cov):\n",
    "#         \"\"\"input multidimensional mean and covariance matrix as numpy arrays\"\"\"\n",
    "#         self.dims = len(mean)\n",
    "#         self.mean = mean\n",
    "#         self.cov = cov\n",
    "#         self.icov = np.linalg.pinv(self.cov, rcond=sys.float_info.epsilon)\n",
    "#         (self.logdetsign, self.logdet) = np.linalg.slogdet(self.cov)\n",
    "\n",
    "#     def logpdf(self, x):\n",
    "#         \"\"\"log probabilities\"\"\"\n",
    "#         delta = x - self.mean\n",
    "#         c = np.dot(delta, np.dot(self.icov, delta))\n",
    "#         prob = -0.5 * c\n",
    "#         return prob\n",
    "\n",
    "#     def sample_ps(self, W):\n",
    "#         \"\"\"W samples directly from distribution\"\"\"\n",
    "#         outsamp = np.random.multivariate_normal(self.mean, self.cov, W)\n",
    "#         return (outsamp, self.mean)\n",
    "\n",
    "#     def sample_gm(self,W):\n",
    "#         \"\"\"W samples around mean of distribution\"\"\"\n",
    "#         outsamp = [self.mean+np.random.randn(self.dims) for w in range(0,W)]\n",
    "#         return (outsamp, self.mean)\n",
    "\n",
    "#     def sample_gs(self, W):\n",
    "#         \"\"\"W samples from a single sample from distribution\"\"\"\n",
    "#         rando = np.random.multivariate_normal(self.mean, self.cov)\n",
    "#         #outsamp = [rando + np.sqrt(rando)*np.random.randn(self.dims) for w in range(0,W)]\n",
    "#         outsamp = [np.random.multivariate_normal(rando,self.cov) for w in range(0,W)]\n",
    "#         return (outsamp, rando)\n",
    "\n",
    "# class post(object):\n",
    "#     \"\"\"\n",
    "#     post object is posterior distribution we wish to sample\n",
    "#     \"\"\"\n",
    "#     def __init__(self,idist,xvals,yprobs,interim):\n",
    "#         \"\"\"data are logged posteriors (ngals*nbins), idist is mvn object\"\"\"\n",
    "#         self.prior = idist\n",
    "#         #self.priormean = idist.mean\n",
    "#         self.interim = interim\n",
    "#         self.xgrid = np.array(xvals)\n",
    "#         self.difs = self.xgrid[1:]-self.xgrid[:-1]#np.array([self.xgrid[k+1]-self.xgrid[k] for k in self.dims])\n",
    "#         self.lndifs = np.log(self.difs)#np.array([m.log(max(self.difs[k],sys.float_info.epsilon)) for k in self.dims])\n",
    "#         self.postprobs = yprobs\n",
    "#         self.constterm = self.lndifs-self.interim#self.priormean\n",
    "#         self.lnprob_ext = post_lnprob\n",
    "\n",
    "#     def priorprob(self,theta):\n",
    "#         \"\"\"this is proportional to log prior probability\"\"\"\n",
    "#         return self.prior.logpdf(theta)\n",
    "\n",
    "#     def lnlike(self,theta):\n",
    "#         \"\"\"specific to N(z) problem\"\"\"\n",
    "#         #return self.lnprob(theta)-self.priorprob(theta)\n",
    "#         constterms = theta+self.constterm\n",
    "#         sumterm = -1.*np.dot(np.exp(theta),self.difs)\n",
    "#         for j in lrange(self.postprobs):\n",
    "#             logterm = np.log(np.sum(np.exp(self.postprobs[j]+constterms)))\n",
    "#             sumterm += logterm\n",
    "#         return sumterm\n",
    "\n",
    "#     def mlnlike(self,theta):\n",
    "#         return -1.*self.lnlike(theta)\n",
    "\n",
    "#     # speed this up some more with matrix magic?\n",
    "#     def lnprob(self,theta):\n",
    "#         \"\"\"calculate log posterior probability\"\"\"\n",
    "# #         constterms = theta+self.constterm\n",
    "# #         sumterm = self.priorprob(theta)-np.dot(np.exp(theta),self.difs)#this should sufficiently penalize poor samples but somehow fails on large datasets\n",
    "# #         for j in lrange(self.postprobs):\n",
    "# #             #logterm = sp.misc.logsumexp(self.postprobs[j]+constterms)#shockingly slower!\n",
    "# #             #logterm = np.logaddexp(self.postprobs[j]+constterms)#only works for two terms\n",
    "# #             logterm = np.log(np.sum(np.exp(self.postprobs[j]+constterms)))\n",
    "# #             sumterm += logterm\n",
    "# #         return sumterm\n",
    "#         return self.lnlike(theta)+self.priorprob(theta)\n",
    "\n",
    "# def post_lnprob(theta, other_self):\n",
    "#     ret = other_self.lnprob(theta)\n",
    "#     return ret\n",
    "\n",
    "# class path(object):\n",
    "#     \"\"\"\n",
    "#     path object takes templates of path style and variables for it and makes os.path objects from them\n",
    "#     \"\"\"\n",
    "#     def __init__(self, path_template, filled = None):\n",
    "#         self.path_template = path_template\n",
    "#         if filled is None:\n",
    "#             self.filled = {}\n",
    "#         else:\n",
    "#             self.filled = filled\n",
    "\n",
    "#     def construct(self, **args):\n",
    "#         \"\"\"actually constructs the final path, as a string.  Optionally takes in any missing parameters\"\"\"\n",
    "#         nfilled = self.filled.copy()\n",
    "#         nfilled.update(args)\n",
    "#         return self.path_template.format(**nfilled)\n",
    "\n",
    "#     def fill(self, **args):\n",
    "#         \"\"\"fills any number of missing parameters, returns new object\"\"\"\n",
    "#         dct = self.filled.copy()\n",
    "#         dct.update(args)\n",
    "#         return path(self.path_template, dct)\n",
    "\n",
    "# class tnorm(object):\n",
    "#     \"\"\"truncated normal distribution object\"\"\"\n",
    "#     def __init__(self,mu,sig,ends):\n",
    "#         self.mu = mu\n",
    "#         self.sig = sig\n",
    "#         (self.min,self.max) = ends\n",
    "#         self.lo = self.loc(self.min)\n",
    "#         self.hi = self.loc(self.max)\n",
    "\n",
    "#     def loc(self,z):\n",
    "#         return (z-self.mu)/self.sig\n",
    "\n",
    "#     def phi(self,z):\n",
    "#         x = z/np.sqrt(2)\n",
    "#         term = sp.special.erf(x)\n",
    "#         return (1.+term)/2.\n",
    "\n",
    "#     def norm(self):\n",
    "#         return max(sys.float_info.epsilon,self.phi(self.hi)-self.phi(self.lo))\n",
    "\n",
    "#     def pdf(self,z):\n",
    "#         x = self.loc(z)\n",
    "#         pdf = sp.stats.norm.pdf(x)\n",
    "#         return pdf/(self.sig*self.norm())\n",
    "\n",
    "#     def cdf(self,z):\n",
    "#         x = self.loc(z)\n",
    "#         cdf = self.phi(x)-self.phi(self.lo)\n",
    "#         return cdf/self.norm()\n",
    "\n",
    "#     def rvs(self,J):\n",
    "#         func = sp.stats.truncnorm(self.lo,self.hi,loc=self.mu,scale=self.sig)\n",
    "#         return func.rvs(size=J)\n",
    "\n",
    "# class gmix(object):\n",
    "#     \"\"\"\n",
    "#     gmix object takes a numpy array of Gaussian parameters and enables computation of PDF\n",
    "#     \"\"\"\n",
    "#     def __init__(self,inarr,bounds):\n",
    "\n",
    "#         self.minZ,self.maxZ = bounds\n",
    "#         self.comps = inarr\n",
    "#         self.ncomps = len(self.comps)\n",
    "\n",
    "#         self.weights = np.transpose(self.comps)[2]\n",
    "# #         mincomps = [(self.minZ-comp[0])/comp[1] for comp in self.comps]\n",
    "# #         maxcomps = [(self.maxZ-comp[0])/comp[1] for comp in self.comps]\n",
    "#         self.comps = [tnorm(comp[0],comp[1],(self.minZ,self.maxZ)) for comp in self.comps]#[sp.stats.truncnorm(mincomps[c],maxcomps[c],loc=self.comps[c][0],scale=self.comps[c][1]) for c in lrange(self.comps)]\n",
    "# #         self.comps = [tnorm(comp[0],comp[1],(self.minZ,self.maxZ)) for comp in self.comps]\n",
    "# #         self.weights = np.array([self.calccdf(c,self.minZ,self.maxZ) for c in lrange(self.comps)])\n",
    "\n",
    "#     def pdfs(self,zs):\n",
    "#         out = np.array([self.weights[c]*np.array([self.comps[c].pdf(z) for z in zs]) for c in xrange(self.ncomps)])\n",
    "#         return out\n",
    "\n",
    "#     def pdf(self,zs):\n",
    "#         return np.sum(self.pdfs(zs),axis=0)\n",
    "\n",
    "#     def cdfs(self,zs):\n",
    "#         out = np.array([self.weights[c]*np.array([self.comps[c].cdf(z) for z in zs]) for c in xrange(self.ncomps)])\n",
    "#         return out\n",
    "\n",
    "#     def cdf(self,zs):\n",
    "#         return np.sum(self.cdfs(zs),axis=0)\n",
    "\n",
    "#     def binned(self,zs):\n",
    "#         thing = self.cdf(zs)\n",
    "#         return thing[1:]-thing[:-1]\n",
    "\n",
    "#     def sample(self,N):\n",
    "#         choices = [0]*self.ncomps\n",
    "#         for j in xrange(N):\n",
    "#             choices[choice(xrange(self.ncomps), self.weights)] += 1\n",
    "#         samps = np.array([])\n",
    "#         for c in xrange(self.ncomps):\n",
    "#             j = choices[c]\n",
    "#             Zs = self.comps[c].rvs(j)\n",
    "#             samps = np.concatenate((samps,Zs))\n",
    "#         return np.array(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# stat-mcmc module calculates intermediate statistics for monitoring state\n",
    "# \"\"\"\n",
    "\n",
    "# import statistics\n",
    "# import numpy as np\n",
    "# import cPickle as cpkl\n",
    "# import os\n",
    "# import scipy as sp\n",
    "# import csv\n",
    "\n",
    "# import utilmcmc as um\n",
    "\n",
    "# class calcstats(object):\n",
    "#     \"\"\"\n",
    "#     object class to set up and calculate summary statistics, unite stats for each output\n",
    "#     \"\"\"\n",
    "#     def __init__(self, meta):\n",
    "#         self.meta = meta\n",
    "#     def update(self, ydata):\n",
    "#         if self.meta.plotonly == False:\n",
    "#             stats = self.compute(ydata)\n",
    "#             self.meta.key.add_stats(self.meta.topdir, self.name, stats)\n",
    "\n",
    "# # # statistics involving both log posterior probabilities and parameter values\n",
    "# # class stat_both(calcstats):\n",
    "# #     \"\"\"\n",
    "# #     calculates statistics that require both posterior probabilities and parameter values: log likelihood ratio and MAP parameter values\n",
    "# #     \"\"\"\n",
    "# #     def __init__(self,meta):\n",
    "# #         calcstats.__init__(self,meta)\n",
    "\n",
    "# #         self.name = 'both'\n",
    "\n",
    "# #         self.ll_stk = self.meta.postdist.lnlike(self.meta.logstkNz)\n",
    "# # #         self.ll_map = self.meta.postdist.lnlike(self.meta.logmapNz)\n",
    "# # #         self.ll_exp = self.meta.postdist.lnlike(self.meta.logexpNz)\n",
    "# #         self.ll_int = self.meta.postdist.lnlike(self.meta.logintNz)\n",
    "# #         self.ll_mml = self.meta.postdist.lnlike(self.meta.logmmlNz)\n",
    "# #         self.ll_smp = []\n",
    "# # #         self.mapvals,self.maps = [],[]\n",
    "\n",
    "# # #         self.llr_stk,self.llr_map,\n",
    "# #         self.llr_stk,self.llr_int,self.llr_mml = [],[],[]\n",
    "\n",
    "# #         outdict = {'ll_stk': self.ll_stk,\n",
    "# # #                   'll_map': self.ll_map,\n",
    "# # #                   'll_exp': self.ll_exp,\n",
    "# #                   'll_int': self.ll_int,\n",
    "# #                   'll_mml': self.ll_mml,\n",
    "# #                   'll_smp': self.ll_smp,\n",
    "# #                   'llr_stk': np.array(self.llr_stk),\n",
    "# # #                   'llr_map': np.array(self.llr_map),\n",
    "# # #                   'llr_exp': np.array(self.llr_exp),\n",
    "# #                   'llr_int': np.array(self.llr_int),\n",
    "# #                   'llr_mml': np.array(self.llr_mml)\n",
    "# #                    }\n",
    "# #         if self.meta.plotonly == False:\n",
    "# #             with open(os.path.join(self.meta.topdir,'stat_both.p'),'wb') as statboth:\n",
    "# #                 cpkl.dump(outdict,statboth)\n",
    "\n",
    "# #     def compute(self,ydata):\n",
    "\n",
    "# #         self.probs = ydata['probs']\n",
    "# #         self.chains = ydata['chains']\n",
    "\n",
    "# # #         where = np.unravel_index(np.argmax(self.probs),(self.meta.nwalkers,self.meta.ntimes))\n",
    "# # #         self.mapvals.append(self.chains[where])\n",
    "# # #         self.maps.append(self.probs[where])\n",
    "\n",
    "# #         self.llr_stk = self.calclr(self.llr_stk,self.ll_stk)\n",
    "# # #         self.llr_map = self.calclr(self.llr_map,self.ll_map)\n",
    "# # #         self.llr_exp = self.calclr(self.llr_exp,self.ll_exp)\n",
    "# #         self.llr_mml = self.calclr(self.llr_mml,self.ll_mml)\n",
    "\n",
    "# #         if self.meta.logtruNz is not None:\n",
    "# #             self.calclr(self.ll_smp,0.)\n",
    "\n",
    "# #         with open(os.path.join(self.meta.topdir,'stat_both.p'),'rb') as indict:\n",
    "# #             outdict = cpkl.load(indict)\n",
    "\n",
    "# #         outdict['llr_stk'] = np.array(self.llr_stk)\n",
    "# # #         outdict['llr_map'] = np.array(self.llr_map)\n",
    "# # #         outdict['llr_exp'] = np.array(self.llr_exp)\n",
    "# #         outdict['llr_mml'] = np.array(self.llr_mml)\n",
    "# #         outdict['ll_smp'] = np.array(self.ll_smp).flatten()/2.\n",
    "# # #         outdict['mapvals'] = np.array(self.mapvals)\n",
    "# # #         outdict['maps'] = np.array(self.maps)\n",
    "\n",
    "# #         with open(os.path.join(self.meta.topdir,'stat_both.p'),'wb') as statboth:\n",
    "# #             cpkl.dump(outdict,statboth)\n",
    "# #         return\n",
    "\n",
    "# #     # likelihood ratio test\n",
    "# #     def calclr(self,var,ll):\n",
    "\n",
    "# #         for w in xrange(self.meta.nwalkers):\n",
    "# #             for x in xrange(self.meta.ntimes):\n",
    "# #                 ll_smp = self.probs[w][x]-self.meta.postdist.priorprob(self.chains[w][x])\n",
    "# #                 var.append(2.*(ll_smp-ll))\n",
    "# # #                 self.llr_stk.append(2.*ll_smp-2.*self.ll_stk)\n",
    "# # #                 self.llr_map.append(2.*ll_smp-2.*self.ll_map)\n",
    "# # #                 self.llr_exp.append(2.*ll_smp-2.*self.ll_exp)\n",
    "# #         return(var)\n",
    "\n",
    "# class stat_chains(calcstats):\n",
    "#     \"\"\"\n",
    "#     calculates statistics that need parameter values: variance, chi^2, KLD; statistics involving parameter values\n",
    "#     \"\"\"\n",
    "#     def __init__(self, meta):\n",
    "#         calcstats.__init__(self, meta)\n",
    "\n",
    "#         self.name = 'chains'\n",
    "\n",
    "#         self.var_ls = []\n",
    "#         self.var_s = []\n",
    "# #         self.vslogstk = None\n",
    "# #         self.vslogmap = None\n",
    "# # #         self.vslogexp = None\n",
    "# #         self.vsstk = None\n",
    "# #         self.vsmap = None\n",
    "# # #         self.vsexp = None\n",
    "\n",
    "#         self.chi_ls = []\n",
    "#         self.chi_s = []\n",
    "# #         self.cslogstk = None\n",
    "# #         self.cslogmap = None\n",
    "# # #         self.cslogexp = None\n",
    "# #         self.csstk = None\n",
    "# #         self.csmap = None\n",
    "# # #         self.csexp = None\n",
    "\n",
    "#         self.kl_stkvtru,self.kl_truvstk = None,None\n",
    "#         self.kl_mapvtru,self.kl_truvmap = None,None\n",
    "#         self.kl_expvtru,self.kl_truvexp = None,None\n",
    "#         self.kl_intvtru,self.kl_truvint = float('inf'),float('inf')\n",
    "#         self.kl_mmlvtru,self.kl_truvmml = float('inf'),float('inf')\n",
    "#         self.kl_smpvtru,self.kl_truvsmp = float('inf'),float('inf')\n",
    "\n",
    "#         if self.meta.logtruNz is not None:\n",
    "# #             vslogstk = self.meta.logstkNz-self.meta.logtruNz\n",
    "# #             self.vslogstk = np.dot(vslogstk,vslogstk)\n",
    "# #             vslogmap = self.meta.logmapNz-self.meta.logtruNz\n",
    "# #             self.vslogmap = np.dot(vslogmap,vslogmap)\n",
    "# # #             vslogexp = self.meta.logexpNz-self.meta.logtruNz\n",
    "# # #             self.vslogexp = np.dot(vslogexp,vslogexp)\n",
    "\n",
    "# #             self.cslogstk = np.average((self.meta.logstkNz-self.meta.logtruNz)**2)\n",
    "# #             self.cslogmap = np.average((self.meta.logmapNz-self.meta.logtruNz)**2)\n",
    "# # #             self.cslogexp = np.average((self.meta.logexpNz-self.meta.logtruNz)**2)\n",
    "\n",
    "#             self.kl_stkvtru,self.kl_truvstk = calckl(self.meta.bindifs,self.meta.logstkNz,self.meta.logtruNz)\n",
    "#             self.kl_mapvtru,self.kl_truvmap = calckl(self.meta.bindifs,self.meta.logmapNz,self.meta.logtruNz)\n",
    "#             self.kl_expvtru,self.kl_truvexp = calckl(self.meta.bindifs,self.meta.logexpNz,self.meta.logtruNz)\n",
    "#             self.kl_intvtru,self.kl_truvint = calckl(self.meta.bindifs,self.meta.logintNz,self.meta.logtruNz)\n",
    "#             self.kl_mmlvtru,self.kl_truvmml = calckl(self.meta.bindifs,self.meta.logmmlNz,self.meta.logtruNz)\n",
    "#             self.kl_smpvtru,self.kl_truvsmp = [],[]\n",
    "\n",
    "# #         if self.meta.truNz is not None:\n",
    "# #             vsstk = meta.stkNz-meta.truNz\n",
    "# #             self.vsstk = np.dot(vsstk,vsstk)\n",
    "# #             vsmap = meta.mapNz-meta.truNz\n",
    "# #             self.vsmap = np.dot(vsmap,vsmap)\n",
    "# # #             vsexp = meta.expNz-meta.truNz\n",
    "# # #             self.vsexp = np.dot(vsexp,vsexp)\n",
    "\n",
    "# #             self.csstk = np.average((self.meta.stkNz-self.meta.truNz)**2)\n",
    "# #             self.csmap = np.average((self.meta.mapNz-self.meta.truNz)**2)\n",
    "# #             self.csexp = np.average((self.meta.expNz-self.meta.truNz)**2)\n",
    "\n",
    "#         outdict = {#'vslogstk': self.vslogstk,\n",
    "# #                    'vsstk': self.vsstk,\n",
    "# #                    'vslogmap': self.vslogmap,\n",
    "# #                    'vsmap': self.vsmap,\n",
    "# # #                    'vslogexp': self.vslogexp,\n",
    "# # #                    'vsexp': self.vsexp,\n",
    "# #                    'cslogstk': self.cslogstk,\n",
    "# #                    'csstk': self.csstk,\n",
    "# #                    'cslogmap': self.cslogmap,\n",
    "# #                    'csmap': self.csmap,\n",
    "# # #                    'cslogexp': self.cslogexp,\n",
    "# # #                    'csexp': self.csexp,\n",
    "#                    'kl_stkvtru': self.kl_stkvtru,\n",
    "#                    'kl_mapvtru': self.kl_mapvtru,\n",
    "#                    'kl_expvtru': self.kl_expvtru,\n",
    "#                    'kl_smpvtru': self.kl_smpvtru,\n",
    "#                    'kl_intvtru': self.kl_intvtru,\n",
    "#                    'kl_mmlvtru': self.kl_mmlvtru,\n",
    "#                    'kl_truvstk': self.kl_truvstk,\n",
    "#                    'kl_truvmap': self.kl_truvmap,\n",
    "#                    'kl_truvexp': self.kl_truvexp,\n",
    "#                    'kl_truvsmp': self.kl_truvsmp,\n",
    "#                    'kl_truvint': self.kl_truvint,\n",
    "#                    'kl_truvmml': self.kl_truvmml\n",
    "#               }\n",
    "#         if self.meta.plotonly == False:\n",
    "#             with open(os.path.join(self.meta.topdir,'stat_chains.p'),'wb') as statchains:\n",
    "#                 cpkl.dump(outdict,statchains)\n",
    "\n",
    "#     def compute(self, ydata):#ntimes*nwalkers*nbins\n",
    "\n",
    "#         self.ydata = ydata\n",
    "#         self.eydata = np.exp(self.ydata)\n",
    "\n",
    "# #         print('about to write samples to file: '+str(self.meta.key.burnin))\n",
    "# #         if self.meta.key.burnin == False:\n",
    "\n",
    "#         with open(self.meta.samples,'ab') as csvfile:\n",
    "#             out = csv.writer(csvfile,delimiter=' ')\n",
    "#             for w in xrange(self.meta.nwalkers):\n",
    "#                 out.writerows(self.ydata[w])#[[x for x in row] for row in self.ydata])\n",
    "# #             print(str(self.meta.key.burnin)+'wrote samples to file')\n",
    "# #         else:\n",
    "# #             print('not writing samples to file because still burning in: '+str(self.meta.key.burnin))\n",
    "\n",
    "#         y = np.swapaxes(self.ydata.T,0,1).T#nwalkers*nbins*ntimes\n",
    "#         ey = np.swapaxes(self.eydata.T,0,1).T#np.exp(y)\n",
    "\n",
    "#         if self.meta.logtruNz is None:\n",
    "#             my = np.array([[[sum(by)/len(by)]*self.meta.ntimes for by in wy] for wy in y])#nwalkers*nbins*ntimes\n",
    "#             mey = np.array([[[sum(bey)/len(bey)]*self.meta.ntimes for bey in wey] for wey in ey])#nwalkers*nbins*ntimes\n",
    "#         else:\n",
    "#             my = np.array([[[k]*self.meta.ntimes for k in self.meta.logtruNz]]*self.meta.nwalkers)#nwalkers*nbins*ntimes\n",
    "#             mey = np.array([[[k]*self.meta.ntimes for k in self.meta.truNz]]*self.meta.nwalkers)#nwalkers*nbins*ntimes\n",
    "\n",
    "#         self.sy = np.swapaxes((y-my),1,2)#nwalkers*ntimes*nbins to #nwalkers*nbins*ntimes\n",
    "#         self.sey = np.swapaxes((ey-mey),1,2)\n",
    "\n",
    "#         self.var_ls = self.calcvar(self.var_ls,self.sy)\n",
    "#         self.var_s = self.calcvar(self.var_s,self.sey)\n",
    "#         self.chi_ls = self.calcchi(self.chi_ls,self.sy,self.ydata)\n",
    "#         self.chi_s = self.calcchi(self.chi_s,self.sey,self.eydata)\n",
    "\n",
    "#         with open(os.path.join(self.meta.topdir,'stat_chains.p'),'rb') as indict:\n",
    "#             outdict = cpkl.load(indict)\n",
    "\n",
    "# #         outdict['kl_smpvtru'] = np.array(self.kl_smpvtru)\n",
    "# #         outdict['kl_truvsmp'] = np.array(self.kl_truvsmp)\n",
    "#         #outdict['tot_var_ls'] = self.tot_var_ls\n",
    "#         #outdict['tot_var_s'] = self.tot_var_s\n",
    "#         outdict['var_ls'] = self.var_ls\n",
    "#         outdict['var_s'] = self.var_s\n",
    "#         #outdict['tot_chi_ls'] = self.tot_chi_ls\n",
    "#         #outdict['tot_chi_s'] = self.tot_chi_s\n",
    "#         outdict['chi_ls'] = self.chi_ls\n",
    "#         outdict['chi_s'] = self.chi_s\n",
    "\n",
    "#         with open(os.path.join(self.meta.topdir,'stat_chains.p'),'wb') as indict:\n",
    "#             cpkl.dump(outdict,indict)\n",
    "#             #print('after addition'+str(outdict))\n",
    "# #         return { 'vslogstk': self.vslogstk,\n",
    "# #                'vsstk': self.vsstk,\n",
    "# #                'vslogmap': self.vslogmap,\n",
    "# #                'vsmap': self.vsmap,\n",
    "# #                'vslogexp': self.vslogexp,\n",
    "# #                'vsexp': self.vsexp,\n",
    "# #                'tot_var_ls': self.tot_var_ls,\n",
    "# #                'tot_var_s': self.tot_var_s,\n",
    "# #                'var_ls': self.var_ls,\n",
    "# #                'var_s': self.var_s\n",
    "# #               }\n",
    "\n",
    "#     def calcvar(self,var,s):\n",
    "#         \"\"\"variance of samples\"\"\"\n",
    "#         ans = np.average([[np.dot(s[w][i],s[w][i]) for i in xrange(len(s[w]))] for w in xrange(len(s))])\n",
    "#         var.append(ans)\n",
    "# #         var_ls = np.average([[np.dot(self.sy[w][i],self.sy[w][i]) for i in xrange(self.meta.ntimes)] for w in xrange(self.meta.nwalkers)])#/float(self.meta.nwalkers*self.meta.ntimes*self.meta.nbins)\n",
    "# #         var_s = np.average([[np.dot(self.sey[w][i],self.sey[w][i]) for i in xrange(self.meta.ntimes)] for w in xrange(self.meta.nwalkers)])#/float(self.meta.nwalkers*self.meta.ntimes*self.meta.nbins)\n",
    "# #         self.var_ls.append(var_ls)\n",
    "# #         self.var_s.append(var_s)\n",
    "#         #self.tot_var_ls = self.tot_var_ls+var_ls\n",
    "#         #self.tot_var_s = self.tot_var_s+var_s\n",
    "#         #print(self.meta.name+' var_ls='+str(self.var_ls))\n",
    "#         #print(self.meta.name+' var_s='+str(self.var_s))\n",
    "#         return(var)\n",
    "\n",
    "#     def calcchi(self,var,s,data):\n",
    "#         \"\"\"chi^2 (or Wald test) of samples\"\"\"\n",
    "#         v = np.sum([np.average([statistics.variance(walk) for walk in data.T[b]]) for b in xrange(len(data.T))])#abs(np.linalg.det(np.cov(flatdata)))\n",
    "#         ans = np.average(s**2)/v\n",
    "#         var.append(ans)\n",
    "\n",
    "# #         flatdata = np.array([self.ydata.T[b].flatten() for b in xrange(self.meta.nbins)])\n",
    "# #         eflatdata = np.exp(flatdata)\n",
    "\n",
    "# #         vy = np.sum([np.average([statistics.variance(walk) for walk in self.ydata.T[b]]) for b in xrange(self.meta.nbins)])#abs(np.linalg.det(np.cov(flatdata)))\n",
    "# #         vey = np.sum([np.average([statistics.variance(walk) for walk in self.eydata.T[b]]) for b in xrange(self.meta.nbins)])#abs(np.linalg.det(np.cov(eflatdata)))\n",
    "\n",
    "# #         chi_ls = np.average(self.sy**2)/vy#np.average(sp.stats.chisquare(flatdata.T)[0])#float(self.meta.nwalkers*self.meta.ntimes*self.meta.nbins*vy)\n",
    "# #         chi_s = np.average(self.sey**2)/vey#np.average(sp.stats.chisquare(eflatdata.T)[0])#float(self.meta.nwalkers*self.meta.ntimes*self.meta.nbins*vey)\n",
    "# #         self.chi_ls.append(chi_ls)\n",
    "# #         self.chi_s.append(chi_s)\n",
    "# #         #self.tot_chi_ls = self.tot_chi_ls+chi_ls\n",
    "# #         #self.tot_chi_s = self.tot_chi_s+chi_s\n",
    "# #         print(self.meta.name+' chi_ls='+str(self.chi_ls))\n",
    "# #         print(self.meta.name+' chi_s='+str(self.chi_s))\n",
    "#         return(var)\n",
    "\n",
    "# class stat_probs(calcstats):\n",
    "#     \"\"\"\n",
    "#     calculates statistics requiring only probabilities:  log posterior probability for alternatives, variance of probabilities\n",
    "#     \"\"\"\n",
    "#     def __init__(self, meta):\n",
    "#         calcstats.__init__(self, meta)\n",
    "#         #self.summary = 0\n",
    "#         self.name = 'probs'\n",
    "\n",
    "# #         # calculating log likelihood ratio test statistic for each relative to truth (and true relative to prior)\n",
    "#         if self.meta.logtruNz is not None:\n",
    "#             self.lp_tru = self.meta.postdist.lnprob(self.meta.logtruNz)\n",
    "#             self.lik_tru = self.meta.postdist.lnlike(self.meta.logtruNz)\n",
    "#         else:\n",
    "#             self.lp_tru = self.meta.postdist.lnprob(self.meta.mean)\n",
    "#             self.lik_tru = self.meta.postdist.lnlike(self.meta.mean)\n",
    "\n",
    "#         self.lp_int = self.meta.postdist.lnprob(self.meta.logintNz)\n",
    "#         self.lp_stk = self.meta.postdist.lnprob(self.meta.logstkNz)\n",
    "#         self.lp_map = self.meta.postdist.lnprob(self.meta.logmapNz)\n",
    "#         self.lp_exp = self.meta.postdist.lnprob(self.meta.logexpNz)\n",
    "#         self.lp_mml = self.meta.postdist.lnprob(self.meta.logmmlNz)\n",
    "\n",
    "#         self.var_y = []\n",
    "\n",
    "#         outdict = {'var_y': self.var_y,\n",
    "#                    'lp_tru': self.lp_tru,\n",
    "#                    'lp_int': self.lp_int,\n",
    "#                    'lp_stk': self.lp_stk,\n",
    "#                    'lp_map': self.lp_map,\n",
    "#                    'lp_exp': self.lp_exp,\n",
    "#                    'lp_mml': self.lp_mml\n",
    "#                   }\n",
    "\n",
    "#         if self.meta.plotonly == False:\n",
    "#             with open(os.path.join(self.meta.topdir,'stat_probs.p'),'wb') as statprobs:\n",
    "#                 cpkl.dump(outdict,statprobs)\n",
    "\n",
    "#     def compute(self, ydata):\n",
    "#         y = np.swapaxes(ydata,0,1).T\n",
    "#         var_y = sum([statistics.variance(y[w]) for w in xrange(self.meta.nwalkers)])/self.meta.nwalkers\n",
    "#         #self.llr_smp.append((2.*np.max(lik_y)-2.*self.ll_tru))\n",
    "#         self.var_y.append(var_y)\n",
    "#         # self.summary = self.summary+var_y\n",
    "\n",
    "#         with open(os.path.join(self.meta.topdir,'stat_probs.p'),'rb') as indict:\n",
    "#             outdict = cpkl.load(indict)\n",
    "\n",
    "#         outdict['var_y'] = self.var_y\n",
    "\n",
    "#         with open(os.path.join(self.meta.topdir,'stat_probs.p'),'wb') as statprobs:\n",
    "#             cpkl.dump(outdict,statprobs)\n",
    "\n",
    "# #         return { #'summary': self.summary,\n",
    "# #                  'var_y': self.var_y,\n",
    "# #                  'lp_tru': self.lp_tru,\n",
    "# # #                  'lp_stk': self.lp_stk,\n",
    "# # #                  'lp_map': self.lp_map,\n",
    "# # # #                  'lp_exp': self.lp_exp\n",
    "# #                  'lp_mml': self.lp_mml\n",
    "# #                }\n",
    "\n",
    "# # class stat_fracs(calcstats):\n",
    "# #     \"\"\"\n",
    "# #     calculates summary statistics on acceptance fractions\n",
    "# #     \"\"\"\n",
    "# #     def __init__(self, meta):\n",
    "# #         calcstats.__init__(self, meta)\n",
    "# #         self.var_y = []\n",
    "# #         self.name = 'fracs'\n",
    "# #     def compute(self, ydata):\n",
    "# #         y = ydata.T\n",
    "# #         var_y = statistics.variance(y)\n",
    "# #         self.var_y.append(var_y)\n",
    "# #         return {'var_y': self.var_y}\n",
    "\n",
    "# class stat_times(calcstats):\n",
    "#     \"\"\"\n",
    "#     calculates summary statistics on autocorrelation times\n",
    "#     \"\"\"\n",
    "#     def __init__(self, meta):\n",
    "#         calcstats.__init__(self, meta)\n",
    "#         self.var_y = []\n",
    "#         self.name = 'times'\n",
    "#     def compute(self, ydata):\n",
    "#         y = ydata.T\n",
    "#         var_y = np.var(y)\n",
    "#         self.var_y.append(var_y)\n",
    "#         return {'var_y': self.var_y}\n",
    "\n",
    "# def cft(xtimes,lag):\n",
    "#     \"\"\"calculate autocorrelation times since emcee sometimes fails\"\"\"\n",
    "#     lent = len(xtimes)-lag\n",
    "#     allt = xrange(lent)\n",
    "#     ans = np.array([xtimes[t+lag]*xtimes[t] for t in allt])\n",
    "#     return ans\n",
    "\n",
    "# def cf(xtimes):#xtimes has ntimes elements\n",
    "#     cf0 = np.dot(xtimes,xtimes)\n",
    "#     allt = xrange(len(xtimes)/2)\n",
    "#     cf = np.array([sum(cft(xtimes,lag)[len(xtimes)/2:]) for lag in allt])/cf0\n",
    "#     return cf\n",
    "\n",
    "# def cfs(x,mode):#xbinstimes has nbins by ntimes elements\n",
    "#     if mode == 'walkers':\n",
    "#         xbinstimes = x\n",
    "#         cfs = np.array([sum(cf(xtimes)) for xtimes in xbinstimes])/len(xbinstimes)\n",
    "#     if mode == 'bins':\n",
    "#         xwalkerstimes = x\n",
    "#         cfs = np.array([sum(cf(xtimes)) for xtimes in xwalkerstimes])/len(xwalkerstimes)\n",
    "#     return cfs\n",
    "\n",
    "# def acors(xtimeswalkersbins,mode):\n",
    "#     if mode == 'walkers':\n",
    "#         xwalkersbinstimes = np.swapaxes(xtimeswalkersbins,1,2)#nwalkers by nbins by nsteps\n",
    "#         taus = np.array([1. + 2.*sum(cfs(xbinstimes,mode)) for xbinstimes in xwalkersbinstimes])#/len(xwalkersbinstimes)# 1+2*sum(...)\n",
    "#     if mode == 'bins':\n",
    "#         xbinswalkerstimes = xtimeswalkersbins.T#nbins by nwalkers by nsteps\n",
    "#         taus = np.array([1. + 2.*sum(cfs(xwalkerstimes,mode)) for xwalkerstimes in xbinswalkerstimes])#/len(xwalkersbinstimes)# 1+2*sum(...)\n",
    "#     return taus\n",
    "\n",
    "# def calckl(difs,lqn,lpn):\n",
    "#     \"\"\"KL Divergence test\"\"\"\n",
    "#     pn = np.exp(lpn)*difs\n",
    "#     qn = np.exp(lqn)*difs\n",
    "#     p = pn/np.sum(pn)\n",
    "#     q = qn/np.sum(qn)\n",
    "#     logp = um.safelog(p)\n",
    "#     logq = um.safelog(q)\n",
    "#     klpq = np.sum(p*(logp-logq))\n",
    "#     klqp = np.sum(q*(logq-logp))\n",
    "#     return(klpq,klqp)\n",
    "\n",
    "# def calcbfe(samples):\n",
    "#     with open(samples,'rb') as csvfile:\n",
    "#         tuples = (line.split(None) for line in csvfile)\n",
    "#         alldata = [[float(pair[k]) for k in range(0,len(pair))] for pair in tuples][1:]\n",
    "#         nbins = len(alldata[0])\n",
    "#         alldata = np.array(alldata).T\n",
    "\n",
    "#     locs,scales = [],[]\n",
    "#     for k in xrange(nbins):\n",
    "#         y_all = alldata[k].flatten()\n",
    "#         loc,scale = sp.stats.norm.fit_loc_scale(y_all)\n",
    "#         locs.append(loc)\n",
    "#         scales.append(scale)\n",
    "#     locs = np.array(locs)\n",
    "#     scales = np.array(scales)\n",
    "#     return(locs,scales)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
