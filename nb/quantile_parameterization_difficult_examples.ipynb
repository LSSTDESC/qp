{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4062665",
   "metadata": {},
   "source": [
    "This notebook explores an example case where the baseline quant_gen parameterization has been shown to be a poor representation of an original PDF - especially as compared to the quant_piecewise_gen (constant) parameterization.\n",
    "\n",
    "Sam Schmidt provided the foundation for this notebook by establishing some input multimodal PDFs with relatively sharp peaks, such that the P(z) value between the peaks was approximately 0. \n",
    "\n",
    "In the first cell, the input PDF is defined, and 51 quantiles are defined for the baseline comparison. The cell also includes the calculation of quantiles such that half are requested number are used to get CDF values, then the second half if used for a linear spacing of CDF values to retrieve quantiles. The two set of (quantile, CDF) pairs are then combined, and used in the examination of the quant_gen parameterization in comparison to the baseline and the quant_piecewise_get parameterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b2e41-93ee-4ef1-b569-2969443236c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qp\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "mu = np.array([[0.0,1.1, 2.9], [0.5, 1.25, 2.8], [0.3, 1.9, 2.2]])\n",
    "sig = np.array([[0.05,0.01,0.04], [0.05,0.01,0.02], [0.025, 0.01, 0.025]])\n",
    "\n",
    "wt = np.array([[1,1,1], [1,1,1], [1,1,1]])\n",
    "\n",
    "def makesamples(mu, sig):\n",
    "    allsamples=np.zeros(5000)\n",
    "    sizes = [1000,3000, 1000]\n",
    "    for i in range(3):\n",
    "        samples = np.array([])\n",
    "        for j in range(3):\n",
    "            tmpnorm = sps.norm(loc=mu[i,j], scale=sig[i,j])\n",
    "            samples=np.hstack((samples, np.array(tmpnorm.rvs(size=sizes[j]))))\n",
    "        samps = np.array(samples).flatten()\n",
    "\n",
    "        allsamples = np.vstack([allsamples, samps])\n",
    "    return allsamples\n",
    "\n",
    "samps = makesamples(mu,sig)\n",
    "goodsamps = samps[1:]\n",
    "\n",
    "# Number of quantiles to use for the baseline comparison\n",
    "num_grid_points_baseline = 51\n",
    "percentiles_baseline = np.linspace(0.001, 0.999, num_grid_points_baseline)\n",
    "pcts_baseline = np.array([np.quantile(goodsamps[x], percentiles_baseline) for x in range(3)])\n",
    "\n",
    "# Half the baseline quantile points are used to define the first set of quantiles.\n",
    "num_grid_points = int(np.ceil(num_grid_points_baseline/2))\n",
    "percentiles = np.linspace(0.001, 0.999, num_grid_points)\n",
    "pcts = np.array([np.quantile(goodsamps[x], percentiles) for x in range(3)])\n",
    "\n",
    "plt.plot(pcts_baseline[1], percentiles_baseline)\n",
    "plt.scatter(pcts[1], percentiles, marker='.')\n",
    "plt.xlim([-0.1,3.5])\n",
    "\n",
    "do_other_percentiles = True\n",
    "if do_other_percentiles:\n",
    "\n",
    "    low = np.mean(pcts[1,0:2]) # mean of the first 2 points\n",
    "    high = np.mean(pcts[1,-2:-1]) # mean of the last two points\n",
    "\n",
    "    # define linear spacing of `num_grid_points` between the low and high CDF values\n",
    "    other_pcts = np.linspace(low, high, num_grid_points)\n",
    "\n",
    "    # use linear interpolation to get the second half of percentile values\n",
    "    # notice the difference on the plot below of the orange dots and blue line.\n",
    "    # if instead we used the CDF function of the distribution, presumably there would be less difference.\n",
    "    # But the spacing of the `percentiles_baseline` vs `percentiles` also plays a role.\n",
    "    interp_function = interp1d(pcts[1], percentiles, kind='linear')\n",
    "    other_percentiles = interp_function(other_pcts)\n",
    "\n",
    "    # plot 'em so you see 'em.\n",
    "    plt.scatter(other_pcts, other_percentiles, marker='.', color='orange')\n",
    "\n",
    "    # combine original and interpolated quants and locations\n",
    "    all_pcts = np.concatenate((pcts[1], other_pcts))\n",
    "    all_percentiles = np.concatenate((percentiles, other_percentiles))\n",
    "\n",
    "    # Sort and select the unique values (to avoid division by 0 errors when calculating derivatives)\n",
    "    inds = np.argsort(all_pcts)\n",
    "\n",
    "    combined_pcts = np.take_along_axis(all_pcts, inds, axis=0)\n",
    "    combined_percentiles = np.take_along_axis(all_percentiles, inds, axis=0)\n",
    "\n",
    "    output_pcts, inds = np.unique(combined_pcts, return_index=True)\n",
    "    output_percentiles = np.take_along_axis(combined_percentiles, inds, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbe39312",
   "metadata": {},
   "source": [
    "Baseline PDf using piecewise linear quantile representation (i.e. `interpolate_multi_x_multi_y` instead of `evaluate_histo_multi_x_multi_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4399d3-b0e7-4146-aa1d-53a974575161",
   "metadata": {},
   "outputs": [],
   "source": [
    "qens = qp.Ensemble(qp.quant,data=dict(quants=percentiles_baseline, locs=pcts_baseline[1]))\n",
    "qens.plot_native(xlim=(0,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1577a470",
   "metadata": {},
   "source": [
    "The following includes the second set of quantiles that are a a linear interpolation between existing (quantile, CDF) pairs. The number of pairs of points for this representations is the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de957bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_other_percentiles:\n",
    "    qens_2d = qp.Ensemble(qp.quant,data=dict(quants=output_percentiles, locs=output_pcts))\n",
    "    qens_2d.plot_native(xlim=(0,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65d7c86a",
   "metadata": {},
   "source": [
    "For reference, the following is the baseline piecewise_constant representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b68544",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_other_percentiles:\n",
    "    qens_pw_const = qp.Ensemble(qp.quant_piecewise,data=dict(quants=output_percentiles, locs=output_pcts))\n",
    "    qens_pw_const.plot_native(xlim=(0,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12d70af6",
   "metadata": {},
   "source": [
    "The following is the original PDF that is being approximated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f051475-b245-493f-9903-6a6311384515",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = qp.Ensemble(qp.mixmod, data=dict(means=mu, stds=sig, weights=wt))\n",
    "ens[1].plot_native(xlim=(0,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2efa7176",
   "metadata": {},
   "source": [
    "The area under the curve is not equal to 1. But it does approache 1 as the number of (quantile, CDF) pairs increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d7aa42-606f-4946-8215-c200cfe5be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(0,3.1,1_000_000)\n",
    "\n",
    "pdf_values = qens.pdf(grid)\n",
    "pdf_values = np.nan_to_num(pdf_values)\n",
    "print(f'Linear-baseline constant gridding integral: {np.trapz(pdf_values, grid)}')\n",
    "\n",
    "pdf_values = qens_2d.pdf(grid)\n",
    "pdf_values = np.nan_to_num(pdf_values)\n",
    "print(f'X/Y sampled CDF gridding integral: {np.trapz(pdf_values, grid)}')\n",
    "\n",
    "pdf_values = qens_pw_const.pdf(grid)\n",
    "pdf_values = np.nan_to_num(pdf_values)\n",
    "print(f'PW constant gridding integral: {np.trapz(pdf_values, grid)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "371127f3",
   "metadata": {},
   "source": [
    "The following is just a single plot showing the original PDF being approximated, the piecewise constant PDF and the X/Y sampled PDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d7098",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = np.linspace(0., 3., 101)\n",
    "pw_pdf = qens_pw_const.pdf(xvals)\n",
    "linear_2d_pdf = qens_2d.pdf(xvals)\n",
    "original_pdf = ens[1].pdf(xvals)\n",
    "\n",
    "fig = ens[1].plot_native(xlim=(0,3), label='Original PDF')\n",
    "\n",
    "fig.plot(xvals, pw_pdf, linestyle='-.', label='Piecewise constant PDF')\n",
    "fig.plot(xvals, linear_2d_pdf, color='blueviolet', linestyle='--', label='X/Y Sampled PDF')\n",
    "fig.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "010ae9a7",
   "metadata": {},
   "source": [
    "The following are plots of residual values. The differences between Original, PW constant, and X/Y sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6529645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2) = plt.subplots(3, 1, sharex=True)\n",
    "ax0.set_xlim([0,3])\n",
    "\n",
    "ax0.plot(xvals, np.squeeze(original_pdf) - pw_pdf, label='Original PDF - Piecewise PDF')\n",
    "ax0.legend()\n",
    "ax1.plot(xvals, pw_pdf - linear_2d_pdf, label='Piecewise PDF - X/Y sampled PDF')\n",
    "ax1.legend()\n",
    "ax2.plot(xvals, np.squeeze(original_pdf) - linear_2d_pdf, label='Original PDF - X/Y sampled PDF')\n",
    "ax2.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qp_issue_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:41:22) [Clang 13.0.1 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9be1a7334e581107f2753dc5e5ebb12b8975e5f80325d35375311bd0b6b51792"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
