{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the BPZ Test Data\n",
    "\n",
    "_Alex Malz & Phil Marshall_\n",
    "\n",
    "We have a small dataset to test our `qp` approximations on: 30,000 photometric redshift 1D posterior PDFs, in \"gridded\" format, from Melissa Graham (UW, LSST). In this notebook we visualize these distributions, and develop machinery to evaluate our approximations on the whole set in \"survey mode.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up, Ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import qp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data file doesn't appear to come with redshifts at which the PDFs are evaluated, but we are told they're evenly spaced between 0.1 and 3.51."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.arange(0.01, 3.51, 0.01, dtype='float')\n",
    "zrange = 3.51-0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PDFs in the data file aren't properly normalized.  In order to be PDFs, we want $\\int\\ p(z)\\ dz=1$, but the data file entries satisfy $\\sum_{z}\\ p(z)=1$, which is not the same.  We approximate the desired integral as $\\int\\ p(z)\\ dz\\ \\approx\\ \\Delta z\\ \\sum_{i}^{N}\\ p(z_{i})$ where $\\Delta z=\\frac{z_{max}-z_{min}}{N}$ is the distance between each neighbor pair $i$ of $N$ redshifts at which the PDF is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('bpz_euclid_test_10_2.probs', 'rb') as data_file:\n",
    "    lines = (line.split(None) for line in data_file)\n",
    "    lines.next()\n",
    "    # lines.next()\n",
    "    pdfs = np.array([[float(line[k]) for k in range(1,len(line))] for line in lines])\n",
    "    pdf_shape = np.shape(pdfs)\n",
    "    #print(np.sum(pdfs, axis=1)[:100] / zrange)\n",
    "    norm_factor = zrange / pdf_shape[1]\n",
    "    pdfs /= norm_factor\n",
    "    print(np.sum(pdfs * zrange, axis=1)[:100])\n",
    "data_file.close()\n",
    "log_pdfs = qp.utils.safelog(pdfs)\n",
    "pdfs = np.exp(log_pdfs)\n",
    "print(np.sum(pdfs, axis=1)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the BPZ $p(z)$'s\n",
    "\n",
    "Let's plot a few interesting PDFs from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = [1, 3, 14, 16, 19, 21]\n",
    "colors = 'rgbcmy'\n",
    "for i in range(len(colors)):\n",
    "    plt.plot(z, pdfs[indices[i]], color=colors[i])\n",
    "plt.xlabel('redshift $z$', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's turn one of them into a `qp.PDF` object initialized with a gridded parametrization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# chosen = random.choice(indices)\n",
    "# print(chosen)\n",
    "\n",
    "chosen=14\n",
    "G = qp.PDF(gridded=(z, pdfs[chosen]))\n",
    "G.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Approximating the BPZ $p(z)'s$\n",
    "\n",
    "\n",
    "Quantile and histogram representations cannot be computed directly from gridded PDFs - we need to make a GMM first, and use this to instantiate a `qp.PDF` object using a `qp.composite` object based on that GMM as `qp.PDF.truth`.  Currently, a GMM can only be fit to samples, so we start by sampling our gridded parametrization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G.sample(1000, vb=False)\n",
    "G.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that there are samples, we can fit the GMM, producing a `qp.composite` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M_dist = G.mix_mod_fit(n_components=2, vb=False)\n",
    "G.plot(vb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `qp.composite` object can be used as the `qp.PDF.truth` to initialize a new `qp.PDF` object that doesn't have any information about the gridded or sample approximations.  Now we can approximate it any way we like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M = qp.PDF(truth=M_dist)\n",
    "M.quantize(vb=False)\n",
    "M.histogramize(vb=False)\n",
    "M.sample(N=100,vb=False)\n",
    "M.plot(vb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Quantifying the Accuracy of the Approximation\n",
    "\n",
    "Let's compute the RMSE and KLD between each approximation and the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare(M, vb=False):\n",
    "    P = qp.PDF(truth=M.truth)\n",
    "    Q = {}\n",
    "    Q['quantiles'] = qp.PDF(quantiles=M.quantize(N=100, vb=vb), vb=vb)\n",
    "    Q['histogram'] = qp.PDF(histogram=M.histogramize(N=100, vb=vb), vb=vb)\n",
    "    Q['samples'] = qp.PDF(samples=M.sample(N=100, vb=vb), vb=vb)\n",
    "    KLD = {}\n",
    "    for approximation in Q.keys():\n",
    "        KLD[approximation] = qp.utils.calculate_kl_divergence(P, Q[approximation], limits=[0.0, 1.0], vb=False)\n",
    "    print KLD\n",
    "    return\n",
    "\n",
    "compare(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
