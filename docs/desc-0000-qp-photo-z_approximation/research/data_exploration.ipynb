{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the BPZ Test Data\n",
    "\n",
    "_Alex Malz & Phil Marshall_\n",
    "\n",
    "We have a small dataset to test our `qp` approximations on: 30,000 photometric redshift 1D posterior PDFs, in \"gridded\" format, from Melissa Graham (UW, LSST). In this notebook we visualize these distributions, and develop machinery to evaluate our approximations on the whole set in \"survey mode.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up, Ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import qp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data file doesn't appear to come with redshifts at which the PDFs are evaluated, but we are told they're evenly spaced between 0.1 and 3.51."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.arange(0.01, 3.51, 0.01, dtype='float')\n",
    "zrange = 3.51 - 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PDFs in the data file aren't properly normalized.  In order to be PDFs, we want $\\int\\ p(z)\\ dz=1$, but the data file entries satisfy $\\sum_{z}\\ p(z)=1$, which is not the same.  We approximate the desired integral as $\\int\\ p(z)\\ dz\\ \\approx\\ \\Delta z\\ \\sum_{i}^{N}\\ p(z_{i})$ where $\\Delta z=\\frac{z_{max}-z_{min}}{N}$ is the distance between each neighbor pair $i$ of $N$ redshifts at which the PDF is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('bpz_euclid_test_10_2.probs', 'rb') as data_file:\n",
    "    lines = (line.split(None) for line in data_file)\n",
    "    lines.next()\n",
    "    # lines.next()\n",
    "    pdfs = np.array([[float(line[k]) for k in range(1,len(line))] for line in lines])\n",
    "    pdf_shape = np.shape(pdfs)\n",
    "    #print(np.sum(pdfs, axis=1)[:100] / zrange)\n",
    "    norm_factor = zrange / pdf_shape[1]\n",
    "    pdfs /= norm_factor\n",
    "    print(np.sum(pdfs * zrange, axis=1)[:100])\n",
    "data_file.close()\n",
    "log_pdfs = qp.utils.safelog(pdfs)\n",
    "pdfs = np.exp(log_pdfs)\n",
    "print(np.sum(pdfs, axis=1)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the BPZ $p(z)$'s\n",
    "\n",
    "Let's plot a few interesting PDFs from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = [1, 3, 14, 16, 19, 21]\n",
    "colors = ['red','green','blue','cyan','magenta','yellow']\n",
    "for i in range(len(colors)):\n",
    "    plt.plot(z, pdfs[indices[i]], color=colors[i], label='Galaxy '+str(indices[i]))\n",
    "plt.xlabel('redshift $z$', fontsize=16)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's turn one of them into a `qp.PDF` object initialized with a gridded parametrization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# chosen = random.choice(indices)\n",
    "# print(chosen)\n",
    "\n",
    "chosen=14\n",
    "G = qp.PDF(gridded=(z, pdfs[chosen]))\n",
    "G.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Approximating the BPZ $p(z)'s$\n",
    "\n",
    "\n",
    "Quantile and histogram representations cannot be computed directly from gridded PDFs - we need to make a GMM first, and use this to instantiate a `qp.PDF` object using a `qp.composite` object based on that GMM as `qp.PDF.truth`.  Currently, a GMM can only be fit to samples, so we start by sampling our gridded parametrization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G.sample(1000, vb=False)\n",
    "G.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that there are samples, we can fit the GMM, producing a `qp.composite` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M_dist = G.mix_mod_fit(n_components=2, vb=False)\n",
    "G.plot(vb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `qp.composite` object can be used as the `qp.PDF.truth` to initialize a new `qp.PDF` object that doesn't have any information about the gridded or sample approximations.  Now we can approximate it any way we like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "M = qp.PDF(truth=M_dist)\n",
    "M.quantize(vb=False)\n",
    "M.histogramize(vb=False)\n",
    "M.sample(N=100,vb=False)\n",
    "M.plot(vb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Quantifying the Accuracy of the Approximation\n",
    "\n",
    "Let's start by computing the RMSE and KLD between each approximation and the truth, in a sample of systems - and then graduate to looking at the estimated $n(z)$. We'll need a function to do all the analysis on a single object, and then accumulate the outputs to analyze them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze(chosen, vb=False, z=None):\n",
    "    \"\"\"\n",
    "    Model the input BPZ P(z) as a GMM, approximate that GMM in \n",
    "    various ways, and assess the quality of each approximation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    chosen : int\n",
    "        ID of galaxy\n",
    "    vb : boolean\n",
    "        Verbose output?\n",
    "    z : float, ndarr\n",
    "        Redshift array for input gridded \"truth\". Used for \n",
    "        evaluating n(z) too\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        Dictionary containing metric values, n(z) on standard \n",
    "        grid, samples, \"true\" GMM gridded p(z).\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    In some cases the GMM does not fit well, leading to bad KLD and \n",
    "    RMSE values when it is compared to the truth.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Make z array if we don't already have it:\n",
    "    if z is None:\n",
    "        z = np.arange(0.01, 3.51, 0.01, dtype='float')\n",
    "\n",
    "    # Make a dictionary to contain the results:     \n",
    "    result = {}\n",
    "    \n",
    "    # Make a GMM model of the input BPZ p(z) (which are stored\n",
    "    # in the global 'pdfs' variable:\n",
    "    G = qp.PDF(gridded=(z, pdfs[chosen]), vb=vb)\n",
    "    \n",
    "    # Draw 1000 samples, fit a GMM model to them, and make a true PDF:\n",
    "    G.sample(1000, vb=vb)\n",
    "    GMM = G.mix_mod_fit(n_components=5, vb=vb)\n",
    "    P = qp.PDF(truth=GMM, vb=vb)\n",
    "    \n",
    "    # Evaluate the GMM on the z grid, and store in the result dictionary. We'll \n",
    "    # need this to make our \"true\" n(z) estimator. We don't need to keep the \n",
    "    # z array, as we passed that in.\n",
    "    result['truth'] = P.evaluate(z, using='truth', vb=vb)[1]\n",
    "\n",
    "    # Now approximate P in various ways, and assess:\n",
    "    Q, KLD, RMSE, approximation = {}, {}, {}, {}\n",
    "    zlimits, dz = [0.0, 3.5], 0.01\n",
    "    Q['quantiles'] = qp.PDF(quantiles=P.quantize(N=100, vb=vb), vb=vb)\n",
    "    Q['histogram'] = qp.PDF(histogram=P.histogramize(N=100, binrange=zlimits, vb=vb), vb=vb)\n",
    "    Q['samples'] = qp.PDF(samples=P.sample(N=100, vb=vb), vb=vb)\n",
    "    for k in Q.keys():\n",
    "        KLD[k] = qp.calculate_kl_divergence(P, Q[k], limits=zlimits, dx=dz, vb=vb)\n",
    "        RMSE[k] = qp.calculate_rmse(P, Q[k], limits=zlimits, dx=dz, vb=vb)\n",
    "        approximation[k] = Q[k].evaluate(z, using=k, vb=vb)[1]\n",
    "        \n",
    "    # Store approximations:\n",
    "    result['KLD'] = KLD\n",
    "    result['RMSE'] = RMSE\n",
    "    result['approximation'] = approximation\n",
    "    result['samples'] = Q['samples'].samples\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = analyze(14, z=z, vb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x['approximation']['quantiles'].shape)\n",
    "print(x['approximation']['histogram'].shape)\n",
    "print(x['approximation']['samples'].shape)\n",
    "print(x['truth'].shape)\n",
    "print(x['samples'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x['samples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now lets's loop over the first 100 galaxies, and look at the distribution of metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = []\n",
    "for i in range(100):\n",
    "    results.append(analyze(i, z=z))\n",
    "    if i%10 == 0: print('.', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is almost certainly a better way of collating the KLD values out of all our results dictionaries than with a for loop, but I don't know what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KLD, RMSE = {}, {}\n",
    "for approximation in results[0]['KLD'].keys():\n",
    "    x = np.array([])\n",
    "    for k in range(len(results)):\n",
    "        x = np.append(x, results[k]['KLD'][approximation])\n",
    "    KLD[approximation] = x\n",
    "    x = np.array([])\n",
    "    for k in range(len(results)):\n",
    "        x = np.append(x, results[k]['RMSE'][approximation])\n",
    "    RMSE[approximation] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot histograms of the metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = {'samples':'red', 'quantiles':'green', 'histogram':'blue'}\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Lefthand panel: KLD\n",
    "plt.subplot(1, 2, 1)\n",
    "bins = np.linspace(0.0, 5, 25)\n",
    "for k in ['samples', 'quantiles', 'histogram']:\n",
    "    plt.hist(KLD[k], bins, label=k, fc=colors[k], ec=colors[k], alpha=0.3)\n",
    "plt.xlabel('KL Divergence Metric', fontsize=16)\n",
    "plt.ylim(0.1, 100.0)\n",
    "plt.legend()\n",
    "\n",
    "# Righthand panel: RMSE\n",
    "plt.subplot(1, 2, 2)\n",
    "bins = np.linspace(0.0, 5, 25)\n",
    "for k in ['samples', 'quantiles', 'histogram']:\n",
    "    plt.hist(RMSE[k], bins, label=k, fc=colors[k], ec=colors[k], alpha=0.3)\n",
    "plt.xlabel('RMS Error Metric', fontsize=16)\n",
    "plt.ylim(0.1, 100.0)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting: looks like the quantile approximation does better in RMSE, but only slightly better in KLD. Histogram does noticeably worse in both metrics.\n",
    "\n",
    "KLD seems to flag more \"bad\" approximations than RMSE. How do we know where to set the threshold in each metric? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets compute the estimated $n(z)$. We'll do this with the GMM \"truth\", and then using each of our approximations. And we'll normalize the $n(z)$ to account for lost systems with bad approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = {}\n",
    "\n",
    "# Pull out all truths and compute the average at each z:\n",
    "x = np.zeros([len(z), len(results)])\n",
    "y = {}\n",
    "for approx in ['samples', 'quantiles', 'histogram']:\n",
    "    y[approx] = np.zeros([len(z), len(results)])\n",
    "    for k in range(len(results)):\n",
    "         y[approx][:,k] = results[k]['approximation'][approx] \n",
    "for k in range(len(results)):\n",
    "    x[:,k] = results[k]['truth'] \n",
    "\n",
    "# Now do the averaging to make the estimators:\n",
    "n['truth'] = np.mean(x, axis=1)\n",
    "for approx in ['samples', 'quantiles', 'histogram']:\n",
    "    n[approx] = np.mean(y[approx], axis=1)\n",
    "\n",
    "# Note: this uses the samples' KDE to make the approximation. We could (and \n",
    "# should!) also try simply concatenating the samples and histogramming them.\n",
    "    \n",
    "# Plot truth and all the approximations. \n",
    "# The NaNs in the histogram approximation make that unplottable for now.\n",
    "plt.plot(z, n['truth'], color='black', lw=4, alpha=0.3, label='truth')\n",
    "for k in ['samples', 'quantiles', 'histogram']:\n",
    "    plt.plot(z, n[k], label=k, color=colors[k])\n",
    "plt.xlabel('redshift z')\n",
    "plt.ylabel('n(z)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"samples\" approximation seems to give a slightly better result for the $n(z)$ estimator than the \"quantiles\" approximation; \"histogram\" is noticeably worse than both. Let's use the `qp.PDF` object to compare them quantitatively (since $n(z)$ can be normalized to give the global $p(z)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = {}\n",
    "for k in ['samples', 'quantiles', 'histogram']:\n",
    "    p[k] = qp.PDF(gridded=(z,n[k]), vb=False)\n",
    "\n",
    "p['truth'] = qp.PDF(gridded=(z,n['truth']), vb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KLD, RMSE = {}, {}\n",
    "zlimits, dz = [0.0, 3.5], 0.01\n",
    "for k in ['samples', 'quantiles', 'histogram']:\n",
    "    KLD[k] = qp.calculate_kl_divergence(p['truth'], p[k], limits=zlimits, dx=dz, vb=False)\n",
    "    RMSE[k] = qp.calculate_rmse(p['truth'], p[k], limits=zlimits, dx=dz, vb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('KLD metrics for n(z) estimator: ', KLD)\n",
    "print('RMSE metrics for n(z) estimator: ', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This early indication suggests that all three approximations are fairly closely matched in this metric. The rank order of the three methods is the same when the $n(z)$ estimates are compared with the KLD metric and the RMSE metric: from best to worst we have \"histogram\", \"samples\" and \"quantiles.\" A bigger test, using the full dataset, should allow this to be tested further: jack-knife error bars shoudl also be calculable. \n",
    "\n",
    "A different set of quantile points maygive a different result. Also, it would be interesting to see whether the conclusions about the choice of approximation vary as the number of available stored values is varied away from 100 (to, perhaps, 3, 10, 30, 100, 300). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
