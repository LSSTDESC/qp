%
% ======================================================================
\RequirePackage{docswitch}
% \flag is set by the user, through the makefile:
%    make note
%    make apj
% etc.
\setjournal{\flag}

\documentclass[\docopts]{\docclass}

% You could also define the document class directly
%\documentclass[]{emulateapj}

% Custom commands from LSST DESC, see texmf/styles/lsstdesc_macros.sty
\usepackage{lsstdesc_macros}

\usepackage{graphicx}
\graphicspath{{./}{./figures/}{.logos}}
\bibliographystyle{apj}

% Add your own macros here:

\newcommand{\textul}{\underline}

%
% ======================================================================

\begin{document}

\title{ Approximating photo-z PDFs for large surveys }

%\maketitlepre

\begin{abstract}

Upcoming and ongoing galaxy surveys will produce redshift probability distribution functions (PDFs) in addition to traditional photometric redshift (photo-$z$) point estimates.  However, the storage of photo-$z$ PDFs may present a challenge as the dataset size increases, as we face a trade-off between the accuracy of subsequent science measurements and the storage cost. We investigate a number of different PDF approximations, using metrics that quantify performance in both large scale structure and weak gravitational lensing studies. In the process, we present \texttt{qp}, a Python library enabling the evaluation of various approximations of 1-dimensional PDFs, as suitable for photometric redshifts.

\end{abstract}

% Keywords are ignored in the LSST DESC Note style:
\dockeys{methods: data analysis, catalogs, surveys}

%\maketitlepost

\FIXME{There's a bug in \texttt{start\_paper} causing the title/authors/abstract to not be rendered.}

% ----------------------------------------------------------------------
%

%\begin{figure}
%\includegraphics[width=0.75\columnwidth]{outline.png}
%\caption{}. \label{fig:outline}}
%\end{figure}

\section{Introduction}
\label{sec:intro}

%This is a paper and note template for the LSST DESC \citep{Overview,ScienceBook,WhitePaper}.
%You can delete all this tutorial text whenever you like.
%
%You can easily switch between various \LaTeX\xspace styles for internal notes and peer reviewed journals.
%Documents can be compiled using the provided \code{Makefile}.
%The command \code{make} with no arguments compiles \code{main.tex} using the  \code{lsstdescnote.cls} style.
%If you want to upgrade your Note into a journal article, just choose a journal name, between \code{make apj} (ApJ preprint format), \code{make apjl} (which uses the \code{emulateapj} style), \code{make prd}, \code{make prl}, and \code{make mnras}.

Ongoing and upcoming photometric galaxy surveys such as the Large Synoptic Survey Telescope (LSST) will observe tens of billions of galaxies without spectroscopic follow-up to obtain redshifts necessary for studies of cosmology and galaxy evolution.  Such surveys rely on the methods of photometric redshift (photo-$z$) estimation.  Photo-$z$s are subject to a number of systematic errors, some caused by the data analysis procedures and others intrinsic to the data itself.  Due to these issues, the photo-$z$ community favors estimation of redshift probability distributions, or photo-$z$ PDFs, that include information about the potential for such systematic errors for each galaxy in the survey.

Given the tremendous size of the surveys in question, storage of these probability distributions raises a number of nontrivial questions.  Previous treatments of photometric redshifts resulted in each galaxy's catalog entry having one additional floating point number to store, or perhaps a few based on a handful of photo-$z$ codes; how many numbers are necessary to characterize a photo-$z$ PDF to the degree of precision dictated by the survey's science goals?  Photo-$z$ PDF codes do not all produce outputs in the same parametrization; what storage format best preserves the characteristics of a photo-$z$ PDF?

Little attention has been paid to these matters, with a few exceptions.  \citep{carrasco_kind_sparse_2014}

In this work, we outline a method by which a survey team may optimize the choice of parametrization and number of stored parameters for an anticipated catalog of photo-$z$ PDFs.  We also present the publicly available \texttt{qp} Python package for performing this optimization for an arbitrary survey.  The approach is demonstrated for LSST mock data.

%[Problem statement: photo-zs, LSST]


% ----------------------------------------------------------------------

%\section{Commands}
%\label{sec:commands}

%There are a number of useful \LaTeX\xspace commands predefined in \code{macros.tex}.
%Notice that the section labels are prefixed with \code{sec:} to allow the use of the \verb=\secref= command to reference a section (\ie, \secref{intro}).
%Figures can be referenced with the \verb=\figref= command, which assumes that the figure label is prefixed with \code{fig:}.
%In \figref{example} we show an example figure.
%You'll notice that the actual figure file is found in the \code{figures} directory.
%However, because we have specified this directory in our \verb=\graphicspath= we do not need to explicitly specify the path to the image.
%
%The \code{macros.tex} package also contains some conventional scientific units like \angstrom, \GeV, \Msun, etc. and some editorial tools for highlighting \FIXME{issues}, \CHECK{text to be checked}, \COMMENT{comments}, and \NEW{new additions}.


% ----------------------------------------------------------------------

\section{Methods}
\label{sec:methods}

[Describe possible interpolation schemes used in conversions for both approximations and metrics]

%Similar to the figure before, here we have included a table of data from \code{tables/table.tex}.
%Notice that again we are able to reference \tabref{example} with the \verb=\tabref= command using the \code{tab:} prefix.
%Also notice that we haven't needed to specify the full path to the table because in the \code{Makefile} we include \code{./tables} directory in the \code{\$TEXINPUTS} environment variable.
%
%\input{table}
%
%Equations appear as follows, and can be referred to as, for example, \eqnref{example} -- just as for tables, we use the \verb=\eqnref= command using the \code{eqn:} prefix.
%\begin{equation}
%  \label{eqn:example}
%  \langle f(k) \rangle = \frac{ \sum_{t=0}^{N}f(t,k) }{N}
%\end{equation}

\texttt{qp} has two main functionalities: converting between parametrizations and computing metrics between two parametrizations.

\subsection{Approximation Methods}
\label{sec:approx}

%[Lay out all parametrizations, pros and cons]

\texttt{qp} is capable of converting a one-dimensional probability distribution between four parametrizations: samples, binning, quantiles, and a mixture model.  Storage of all these parametrizations have been used in the literature, except for quantiles, which have never before been investigated for this purpose.

\COMMENT{}\citet{carrasco_kind_sparse_2014} also considers point estimators derived from PDFs.  I will need to implement this for the PZ DC1 paper.  Should I include that in this paper?}

We do not consider the sparse basis representation of \citet{carrasco_kind_sparse_2014} for several reasons.  It assumes that the native format of a photo-$z$ PDF is evaluations on a grid, which is not in general true.  There is no guarantee that the resulting combination of basis functions satisfies the definition of a probability distribution (normalization to unity and nonnegativity) -- it does not take advantage of the fact that photo-$z$ PDFs are probability distributions rather than arbitrary functions.  \COMMENT{I also thought it required extensive computational resources, but it appears to be a lot faster than \texttt{qp} making quantiles with the same number of parameters -- recall that calculating quantiles generally requires an optimization.  My reasons are pretty weak; if I had more time I'd have \texttt{qp} employ the \texttt{SparsePz} method as another parametrization, but I don't know when I'll be able to do it!}

\subsubsection{Samples}
\label{sec:samples}

\subsubsection{Regular Binning}
\label{sec:bins}

\subsubsection{Regular Quantiles}
\label{sec:quantiles}

\subsubsection{Mixture Model}
\label{sec:gmm}

\subsection{Comparison Metrics}
\label{sec:metrics}

%[Lay out all metrics considered, pros and cons]

We use several metrics to quantify how well an approximation of a photo-$z$ PDF reconstructed from a stored format represents the true photo-$z$ PDF before it was compressed.

\COMMENT{\citet{carrasco_kind_sparse_2014} uses histograms and summary statistics of the RMSE distribution.  Should we also do that or is it sufficient to interpret the metrics on $\hat{n}(z)$ in terms of percent error?}

\subsubsection{RMSE}
\label{sec:rms}

The root mean square error (RMSE) is a familiar measure of the difference between two functions.  The

\subsubsection{KLD}
\label{sec:kld}

The Kullback-Leibler divergence quantifies the deviation of one distribution from another, which in our case is the distance to a true distribution $P$ from an approximation thereof $P'$, as in
\begin{align}
  D(P' | P) &= \int_{-\infty}^{\infty}\ \log\left[\frac{P(z)}{P'(z)}\right]\ P(z)\ dz.
\end{align}

%\subsubsection{Moments}
%\label{sec:moments}

%\subsubsection{KS}
%\label{sec:ks}

% ----------------------------------------------------------------------

\section{Photo-z Test Data}
\label{sec:data}

With the understanding that \texttt{qp} may suggest a different optimal result for different datasets, we apply it to two mock datasets with different data quality properties.

\COMMENT{\citet{carrasco_kind_sparse_2014} uses $10^{6}$ galaxies.}

\subsection{LSST+Euclid mocks}
\label{sec:mg}

\subsection{LSST mocks}
\label{sec:ss}

%\subsection{Simulation}
%\label{sec:mock}

%["Observed" $z_{s}$ vs. $z_{p}$ (from Buzzard)]

%\begin{figure}
%%\includegraphics[width=0.9\columnwidth]{}
%\caption{[plot of $z_{s}$ vs. $z_{p}$]\label{fig:observed}}
%\end{figure}

%[Fit $z_{s}$ vs. $z_{p}$ with bivariate GMM]

%\begin{figure}
%%\includegraphics[width=0.9\columnwidth]{}
%\caption{[$z_{s}$ vs. $z_{p}$ contour plot after GMM fit]\label{fig:fit}}
%\end{figure}

%[Specify true $n(z)$]

%\begin{figure}
%%\includegraphics[width=0.9\columnwidth]{}
%\caption{[chosen true $n(z)$]\label{fig:nz}}
%\end{figur}

%\subsection{Catalog generation}
%\label{sec:catalogs}

%[Choose catalog size $N$ and sample $z_{s}$ values from true $n(z)$]

%[Evaluate $N$ "true" $p(z)$s from horizontal cuts in fitted $z_{s}$ vs. $z_{p}$; these are \texttt{qp.catalog} objects comprised of \texttt{qp.PDF} objects defined by original GMM formulae]

%\begin{figure}
%%\includegraphics[width=0.9\columnwidth]{}
%\caption{[Some example $p(z)$s]\label{fig:pzs}}
%\end{figure}

%[Convert into parametrizations as separate catalogs]

% ----------------------------------------------------------------------

\section{Science Metrics}
\label{sec:science}



\subsection{$\hat{n}(z)$}
\label{sec:nz}

\begin{align}
\hat{n}(z) &= \frac{1}{N}\sum_{i=1}^{N}p_{i}(z)
\label{eq:nz}
\end{align}

%\subsection{$\Sigma_{crit}^{-1}$}
%\label{sec:sigma}

%\citet{dark_energy_survey_collaboration_redshift_2016}

%\begin{align}
%\Sigma_{crit}^{-1} &= \frac{4\pi G}{c}\frac{D_{ls}D_{l}}{D_{s}}
%\label{eq:sigma}
%\end{align}

%\begin{align}
%\left\langle\Sigma_{crit}^{-1}\right\rangle(z_{lens}) &= \sum_{i=1}^{N}p(z_{source, i})\Sigma_{crit}^{-1}(z_{lens}, z_{source, i})
%\label{eq:meansigma}
%\end{align}

% ----------------------------------------------------------------------

\section{Results}
\label{sec:results}

%\figref{example} shows an example figure, referred to with the \verb=\figref= command and the \code{fig:} prefix.
%
%\begin{figure}
%\includegraphics[width=0.9\columnwidth]{example.png}
%\caption{An example figure: the LSST DESC logo, copied from \code{.logos/desc-logo.png} into \code{figures/example.png}. \label{fig:example}}
%\end{figure}

[Multipanel key plot commentary]

\begin{figure}
%\includegraphics[width=0.9\columnwidth]{}
\caption{[number of stored floats $N_{f}$ vs. metric, one curve per approximation method]\label{fig:results}}
\end{figure}

% ----------------------------------------------------------------------

%\section{Discussion}
%\label{sec:discussion}
%
%If you are planning on committing your paper to GitHub, it's a good idea to write your tex as one sentence per line.
%This allows for an easier \code{diff} of changes.
%It also makes sense to think of latex as \emph{code}, and sentences as logical statements, occupying one line each.
%Each line must ``compile'' in the mind of the reader.


% ----------------------------------------------------------------------

\section{Conclusions \& Future Directions}
\label{sec:conclusions}

%Here's a summary of what we just reported.
%
%We can draw the following well-organized and neatly-formatted conclusions:
%\begin{itemize}
%  \item This is important.
%  \item We can measure some number with some precision.
%  \item This has some implications.
%\end{itemize}
%
%Here are some parting thoughts.

% ----------------------------------------------------------------------

This work addresses the tradeoff between the accuracy of stored photo-$z$ PDFs and the footprint of the data needed to encode the photo-$z$ PDFs.  It does not address the computational resources necessary to perform the storage operation nor to unpack the stored information into the form necessary for science computations.

Further applications of \texttt{qp} functionality for manipulations of photo-$z$ PDFs is demonstrated in the LSST-DESC PZ DC1 paper (in prep.).

\subsection*{Acknowledgments}

%Here is where you should add your specific acknowledgments, remembering that some standard thanks will be added via the \code{acknowledgments.tex} and \code{contributions.tex} files.

We thank Melissa Graham and Sam Schmidt for providing the mock datasets.

\input{acknowledgments}

\input{contributions}

%{\it Facilities:} \facility{LSST}

% Include both collaboration papers and external citations:
\bibliography{lsstdesc,main}
%\bibliography{qp}

\end{document}
% ======================================================================
%
